{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zy/w6vdj9192wq63z7s4tnwgr4m0000gp/T/ipykernel_35877/2256478859.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtqdm\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mv1\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_verbosity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mERROR\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Hide TF deprecation messages\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)  # Hide TF deprecation messages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import modules\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chair_meshes_paths = list(glob(\"chairs_ngon/*.obj\"))\n",
    "with open(\"chairs_split_dict.pickle\", 'rb') as f:\n",
    "    chairs_split_dict = pickle.load(f)\n",
    "chairs_train = []\n",
    "chairs_val = []\n",
    "chairs_test = []\n",
    "for c in chair_meshes_paths:\n",
    "    try:\n",
    "        split = chairs_split_dict[c.split(\"/\")[-1].replace(\".obj\", \"\")]\n",
    "    except KeyError:\n",
    "#         print(c.split(\"/\")[-1].replace(\".obj\", \"\"))\n",
    "        continue\n",
    "    if split =='train':\n",
    "        chairs_train.append(c)\n",
    "    elif split =='val':\n",
    "        chairs_val.append(c)\n",
    "    else:\n",
    "        chairs_test.append(c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_paths = chairs_train\n",
    "val_paths = chairs_val\n",
    "max_length = 30"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "captions = pd.read_csv(\"captions_tablechair.csv\").dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_captions=[]\n",
    "for index, row in captions.iterrows():\n",
    "    try:\n",
    "        # if row[\"category\"]==\"Table\":\n",
    "        #     if tables_split_dict[row[\"modelId\"]]=='train':\n",
    "        #         train_captions.append(row['description'])\n",
    "        if row[\"category\"]==\"Chair\":\n",
    "            if chairs_split_dict[row[\"modelId\"]]=='train':\n",
    "                train_captions.append(row['description'])\n",
    "    except KeyError:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(train_captions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def text2shape(paths, captions, tokenizer):\n",
    "    for path in paths:\n",
    "        # with open(path, 'rb') as obj_file:\n",
    "        mesh_dict = data_utils.load_process_mesh(path)\n",
    "#         mesh_dict['class_label'] = 18 if cls==\"Chair\" else 49\n",
    "        if len(mesh_dict['vertices'])>500:\n",
    "            continue\n",
    "        if len(mesh_dict['faces'])>2600:\n",
    "            continue\n",
    "        # mesh_dict = random_scaling(mesh_dict)\n",
    "        try:\n",
    "            text = captions[captions[\"modelId\"]==path.split(\"/\")[-1].replace(\".obj\", \"\")].sample(n=1)[\"description\"].values[0]\n",
    "        except:\n",
    "            continue\n",
    "        text = text.lower().replace(\"the\", '').replace(\"a\", '').replace(\"of\", '').replace(\"for\", '').replace(\"and\", '').replace(\"to\", '').replace(\"in\", '')\n",
    "        text = \" \".join(text.split(\" \")[:max_length])\n",
    "        text = tokenizer.texts_to_sequences([text])[0]\n",
    "        mesh_dict['text_feature'] = np.pad(text, (0,max_length-len(text)))\n",
    "        yield mesh_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Text2ShapeDatasetVal = tf.data.Dataset.from_generator(\n",
    "        lambda:text2shape(val_paths, captions, tk),\n",
    "        output_types={\n",
    "            'vertices': tf.int32, 'faces': tf.int32,\n",
    "#             'class_label': tf.int32,\n",
    "            'text_feature': tf.int32},\n",
    "        output_shapes={\n",
    "            'vertices': tf.TensorShape([None, 3]), 'faces': tf.TensorShape([None]),\n",
    "#             'class_label': tf.TensorShape(()),\n",
    "            'text_feature':tf.TensorShape(max_length)})\n",
    "vertex_model_dataset_val = data_utils.make_vertex_model_dataset(Text2ShapeDatasetVal, apply_random_shift=False)\n",
    "vertex_model_dataset_val = vertex_model_dataset_val.repeat()\n",
    "vertex_model_dataset_val = vertex_model_dataset_val.padded_batch(BATCH_SIZE, padded_shapes=vertex_model_dataset_val.output_shapes)\n",
    "vertex_model_dataset_val = vertex_model_dataset_val.prefetch(1)\n",
    "itv = vertex_model_dataset_val.make_initializable_iterator()\n",
    "vertex_model_batch_val = itv.get_next()\n",
    "iterator_init_op_val = itv.initializer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vertex_model = modules.TextToVertexModel(\n",
    "    decoder_config=dict(\n",
    "      hidden_size=128,\n",
    "      fc_size=512,\n",
    "      num_heads=8,\n",
    "      layer_norm=True,\n",
    "      num_layers=24,\n",
    "      dropout_rate=0.4,\n",
    "      re_zero=True,\n",
    "      memory_efficient=True\n",
    "      ),\n",
    "    path_to_embeddings=\"glove.6B/glove.6B.100d.txt\",\n",
    "    embedding_dims = 100,\n",
    "    quantization_bits=8,\n",
    "    tokenizer=tk,\n",
    "    max_num_input_verts=500,  # number of vertices in the input mesh, if this is lower than the number of vertices in the mesh, there will be errors during training\n",
    "    use_discrete_embeddings=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# vertex_model_pred_dist_val = vertex_model(vertex_model_batch_val)\n",
    "# vertex_model_loss_val = -tf.reduce_sum(\n",
    "#     vertex_model_pred_dist_val.log_prob(vertex_model_batch_val['vertices_flat']) *\n",
    "#     vertex_model_batch_val['vertices_flat_mask'])\n",
    "vertex_samples_val = vertex_model.sample(\n",
    "    1, context=vertex_model_batch_val, max_sample_length=500, top_p=0.95,\n",
    "    recenter_verts=False, only_return_complete=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "face_module_config=dict(\n",
    "  encoder_config=dict(\n",
    "      hidden_size=512,\n",
    "      fc_size=2048,\n",
    "      num_heads=8,\n",
    "      layer_norm=True,\n",
    "      num_layers=10,\n",
    "      dropout_rate=0.2,\n",
    "      re_zero=True,\n",
    "      memory_efficient=True,\n",
    "      ),\n",
    "  decoder_config=dict(\n",
    "      hidden_size=512,\n",
    "      fc_size=2048,\n",
    "      num_heads=8,\n",
    "      layer_norm=True,\n",
    "      num_layers=14,\n",
    "      dropout_rate=0.2,\n",
    "      re_zero=True,\n",
    "      memory_efficient=True,\n",
    "      ),\n",
    "  class_conditional=False,\n",
    "  decoder_cross_attention=True,\n",
    "  use_discrete_vertex_embeddings=True,\n",
    "  max_seq_length=8000,\n",
    "  )\n",
    "face_model=modules.FaceModel(**face_module_config)\n",
    "face_samples_val = face_model.sample(\n",
    "    context=vertex_samples_val, max_sample_length=2000, top_p=0.95,\n",
    "    only_return_complete=True)\n",
    "face_model_saver = tf.train.Saver(var_list=face_model.variables)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "saver_vertex = tf.train.Saver(var_list=vertex_model.variables)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mesh_list = []\n",
    "num_samples_complete = 0\n",
    "num_samples_min = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  saver_vertex.restore(sess, \"text_vertex/last-141\")\n",
    "  face_model_saver.restore(sess, \"face_model/model\")\n",
    "  mesh_list = []\n",
    "  num_samples_complete = 0\n",
    "  while num_samples_complete < num_samples_min:\n",
    "    v_samples_np = sess.run(vertex_samples_val)\n",
    "    print(vertex_samples_val['text_feature'])\n",
    "    if v_samples_np['completed'].size == 0:\n",
    "      print('No vertex samples completed in this batch. Try increasing ' +\n",
    "            'max_num_vertices.')\n",
    "      continue\n",
    "    f_samples_np = sess.run(\n",
    "        face_samples_val,\n",
    "        {vertex_samples_val[k]: v_samples_np[k] for k in vertex_samples_val.keys()})\n",
    "    v_samples_np = f_samples_np['context']\n",
    "    num_samples_complete_batch = f_samples_np['completed'].sum()\n",
    "    num_samples_complete += num_samples_complete_batch\n",
    "    print('Num. samples complete: {}'.format(num_samples_complete))\n",
    "    for k in range(num_samples_complete_batch):\n",
    "      verts = v_samples_np['vertices'][k][:v_samples_np['num_vertices'][k]]\n",
    "      faces = data_utils.unflatten_faces(\n",
    "          f_samples_np['faces'][k][:f_samples_np['num_face_indices'][k]])\n",
    "      mesh_list.append({'vertices': verts, 'faces': faces})\n",
    "\n",
    "\n",
    "data_utils.plot_meshes(mesh_list, ax_lims=0.4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
