{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T18:05:32.082630400Z",
     "start_time": "2023-07-13T18:05:24.717702700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 23:26:30.787185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)  # Hide TF deprecation messages\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import modules\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:20.020635900Z",
     "start_time": "2023-07-12T23:13:20.004836800Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tensorflow import summary as s\n",
    "log_dir = \"logs/text/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# summary_writer = s.FileWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:20.161258600Z",
     "start_time": "2023-07-12T23:13:20.020635900Z"
    }
   },
   "outputs": [],
   "source": [
    "chair_meshes_paths = list(glob(\"chairs_ngon/*.obj\"))\n",
    "# chair_meshes_paths = [[\"Chair\", path] for path in chair_meshes_paths]\n",
    "tables_meshes_paths = list(glob(\"tables_ngon/*.obj\"))\n",
    "# tables_meshes_paths = [[\"Table\", path] for path in tables_meshes_paths]\n",
    "# chair_meshes_paths.extend(tables_meshes_paths)\n",
    "# paths = chair_meshes_paths.copy()\n",
    "# random.shuffle(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"chairs_split_dict.pickle\", 'rb') as f:\n",
    "    chairs_split_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tables_split_dict.pickle\", 'rb') as f:\n",
    "    tables_split_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d6075b23895c7d0880e85c92fa2351f7\n",
      "248e014f31771b31d3ddfaaa242f81a1\n",
      "a27b9f94d052176af27383fc5a5a711c\n",
      "b0fdc43b0b4e990719abd93be2967664\n",
      "1ff1912cc74a76c3b2152dcc3ff6a477\n",
      "f4a0d0169abf306a754ec1f2eef2c6cc\n",
      "b625936e3db6af6318df1fa50d2b64c\n",
      "b6305089d351329681dff5c2e57ad46e\n",
      "a680830f8b76c1bbe929777b2f481029\n",
      "1512e3c41de7a461e10a48f2bbb9bef4\n",
      "a1dbdff3da83425f3eec26c23f5bc80b\n",
      "4afbcdeba648df2e19fb4103277a6b93\n",
      "619a795a84e2566ac22e965981351403\n",
      "9faefdf6814aaa975510d59f3ab1ed64\n",
      "13d3462293023fe71f530727405d60cf\n",
      "d851b8a016cf114c742f75bc7df727ae\n",
      "3319a9b24416ecea7ff6ace05b36a5\n",
      "122a480cfcdd742650c626aa72455dae\n",
      "b233a919f5d2f6ac2ad490d4d7fae486\n",
      "702cebffa33a19f019f079d1b712f46f\n",
      "8967e65c1541d1874aa7f42ef07f614e\n",
      "374fe2584abb594da094848ea4d06501\n",
      "de2bb45b7e200d6916d102513d0383c0\n",
      "38fed916a35dd43d7c8c503b4b873379\n",
      "c73d63f9080e84a91b17743c18fb63dc\n",
      "bf01483d8b58f0819767624530e7fce3\n",
      "29f890e465741b7ef8cb9d3fa2bcdc0\n",
      "32563c1b8b31667bb6695fcbbfeb161b\n",
      "263f629d385be2b1601104cd2d998272\n",
      "b5b77de7a8a05ab4f09df371fae9d63d\n",
      "3dadf67ebe6c29a3d291861d5bc3e7c8\n",
      "b54d0fbc33d125bb7a6d149f6c9151a9\n",
      "7051b028c8c1facfced9bf2a92246703\n",
      "20b8c6959784f2da83b763ebf4ad2b38\n",
      "640aadadf4fcba8355f9a00acc25f137\n",
      "2ab4b8a3fe51d2ba1b17743c18fb63dc\n",
      "2314a3400230f50d14038d588fd1342f\n",
      "d8892d8a902616b1669e5c8c05e138e9\n",
      "3ff4401d898b488a601104cd2d998272\n",
      "218233bd68f5261dff318cdb0cb45ca\n",
      "708e7253604979d06d83c04495f2aa08\n",
      "8a9630332c2cb42644ac83b3e97ad658\n",
      "131edf0948b60ee6372c8cd7d07d8ddc\n",
      "e9821fb7af7db92b26f6c8b5b75f0ee9\n",
      "4521ce028e5009811866a0bc19f46a1d\n",
      "47da08d9c7cd7e104b3c42e318f3affc\n",
      "7c68894c83afb0118e8dcbd53cc631ab\n",
      "1924\n",
      "340\n",
      "637\n"
     ]
    }
   ],
   "source": [
    "chairs_train = []\n",
    "chairs_val = []\n",
    "chairs_test = []\n",
    "for c in chair_meshes_paths: \n",
    "    try:\n",
    "        split = chairs_split_dict[c.split(\"/\")[-1].replace(\".obj\", \"\")]\n",
    "    except KeyError:\n",
    "        print(c.split(\"/\")[-1].replace(\".obj\", \"\"))\n",
    "        continue\n",
    "    if split =='train':\n",
    "        chairs_train.append(c)\n",
    "    elif split =='val':\n",
    "        chairs_val.append(c)\n",
    "    else:\n",
    "        chairs_test.append(c)\n",
    "print(len(chairs_train))\n",
    "print(len(chairs_val))\n",
    "print(len(chairs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7c770e38383d59be279e896561802d26\n",
      "90a2174624d8b62da53326e496617646\n",
      "74983e99e7606eb114708467db3d00e2\n",
      "eeb6784f5812bcebb281680297eb79f2\n",
      "d6580bbf1220d39ede270fc3c23d78b\n",
      "4e3d100672af00842dc02296076d8ee0\n",
      "3b7fc97192e483ebb0bf045ee98272fc\n",
      "812665596d6c13b1adeb1694faeea26\n",
      "ba4ffdf3eed29dea9f8c3d2002c77ddb\n",
      "702cebffa33a19f019f079d1b712f46f\n",
      "5a6e7c4fb53f27925d3bb412062af8d4\n",
      "4b6276df295b3967601104cd2d998272\n",
      "6550c93bce51b9b4719088c8e42c6ab\n",
      "244955211c2f3b94b821b834431f4e0e\n",
      "67bee18dec77f305e4af5827e8177766\n",
      "35e62b9c23928bc57f5df2bc47846a54\n",
      "683ddfb4cf9c8f2883f21c04f5e0acd2\n",
      "ecd56b7b86c4d94ad1f278e1513f3b7\n",
      "4d24a0d4ed77db9f4b3c42e318f3affc\n",
      "cca18c7f8636606f51f77a6d7299806\n",
      "8b8152865839a79719fb4103277a6b93\n",
      "80b20fdbf1183f37b7491f8d3451cded\n",
      "8d4693c04d684e61a3430e4fb40c91fe\n",
      "79fba03fadd8c00ef10b04ee8b1c6914\n",
      "537a02eff282b33df58bc14da5676759\n",
      "27fd962813feeb26be25fbd47cafc694\n",
      "2fc468b98c0cd227c8830fa1ef6e3e71\n",
      "d3b644f9eb32ec9cbe1fb1bc0addfcca\n",
      "4d1d28d15b19f9101e0e41d96d3d0a78\n",
      "3d95c4ebb88f94b3d2f054448bd437d6\n",
      "f39401db6cc45a3ae3e15116d1de599a\n",
      "6d4fad5487a044249dc30bab479ad5d4\n",
      "38ea17d177c4e872fd07832c54eb7e78\n",
      "564474f25a4400c5dc20930e6fc85682\n",
      "3746\n",
      "571\n",
      "1171\n"
     ]
    }
   ],
   "source": [
    "tables_train = []\n",
    "tables_val = []\n",
    "tables_test = []\n",
    "for c in tables_meshes_paths: \n",
    "    try:\n",
    "        split = tables_split_dict[c.split(\"/\")[-1].replace(\".obj\", \"\")]\n",
    "    except KeyError:\n",
    "        print(c.split(\"/\")[-1].replace(\".obj\", \"\"))\n",
    "        continue\n",
    "    if split =='train':\n",
    "        tables_train.append(c)\n",
    "    elif split =='val':\n",
    "        tables_val.append(c)\n",
    "    else:\n",
    "        tables_test.append(c)\n",
    "print(len(tables_train))\n",
    "print(len(tables_val))\n",
    "print(len(tables_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chairs_train.extend(tables_train)\n",
    "train_paths = chairs_train.copy()\n",
    "random.shuffle(train_paths)\n",
    "# train_paths = train_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = len(train_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chairs_val.extend(tables_val)\n",
    "val_paths = chairs_val.copy()\n",
    "random.shuffle(val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = len(val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:20.346341600Z",
     "start_time": "2023-07-12T23:13:20.161258600Z"
    }
   },
   "outputs": [],
   "source": [
    "captions = pd.read_csv(\"captions_tablechair.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>modelId</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>topLevelSynsetId</th>\n",
       "      <th>subSynsetId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118462</td>\n",
       "      <td>e702f89ce87a0b6579368d1198f406e7</td>\n",
       "      <td>the table is round and has 3 legs. the table i...</td>\n",
       "      <td>Table</td>\n",
       "      <td>4379243</td>\n",
       "      <td>4379243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118461</td>\n",
       "      <td>b654fef8eb98e99d65ba78ad9601cf1b</td>\n",
       "      <td>the chair is made of plastic and has 4 legs, i...</td>\n",
       "      <td>Chair</td>\n",
       "      <td>3001627</td>\n",
       "      <td>4331277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118460</td>\n",
       "      <td>df5b55da209637624b3c42e318f3affc</td>\n",
       "      <td>It is narrow console table.It is made from ply...</td>\n",
       "      <td>Table</td>\n",
       "      <td>4379243</td>\n",
       "      <td>3092883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118459</td>\n",
       "      <td>791c14d53bd565f56ba14bfd91a75020</td>\n",
       "      <td>A simple chair with wooden back rest and seati...</td>\n",
       "      <td>Chair</td>\n",
       "      <td>3001627</td>\n",
       "      <td>20000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118458</td>\n",
       "      <td>6730f663d0e012506f525e79a05bbcb3</td>\n",
       "      <td>It is simple chiar with comfortable back rest ...</td>\n",
       "      <td>Chair</td>\n",
       "      <td>3001627</td>\n",
       "      <td>20000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75355</th>\n",
       "      <td>23226</td>\n",
       "      <td>10fbf670bb017ec94ebb593f0d0b4581</td>\n",
       "      <td>A tall table used for decoration</td>\n",
       "      <td>Table</td>\n",
       "      <td>4379243</td>\n",
       "      <td>3092883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75356</th>\n",
       "      <td>23213</td>\n",
       "      <td>bae518da1e709e83596f70d1d7edd4bc</td>\n",
       "      <td>Confortable and adjustable chair probably made...</td>\n",
       "      <td>Chair</td>\n",
       "      <td>3001627</td>\n",
       "      <td>4373704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75357</th>\n",
       "      <td>23185</td>\n",
       "      <td>bae518da1e709e83596f70d1d7edd4bc</td>\n",
       "      <td>The chair is unique and adjustable.  There is ...</td>\n",
       "      <td>Chair</td>\n",
       "      <td>3001627</td>\n",
       "      <td>4373704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75358</th>\n",
       "      <td>23159</td>\n",
       "      <td>1ef6c2b9d413fb7c681404257d94ad9</td>\n",
       "      <td>Wooden table with four legs and a centerpiece ...</td>\n",
       "      <td>Table</td>\n",
       "      <td>4379243</td>\n",
       "      <td>4379243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75359</th>\n",
       "      <td>23142</td>\n",
       "      <td>171a3677999c79b32c8109e73b98d509</td>\n",
       "      <td>Nice long table to fit the whole family.</td>\n",
       "      <td>Table</td>\n",
       "      <td>4379243</td>\n",
       "      <td>4379243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75358 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                           modelId  \\\n",
       "0      118462  e702f89ce87a0b6579368d1198f406e7   \n",
       "1      118461  b654fef8eb98e99d65ba78ad9601cf1b   \n",
       "2      118460  df5b55da209637624b3c42e318f3affc   \n",
       "3      118459  791c14d53bd565f56ba14bfd91a75020   \n",
       "4      118458  6730f663d0e012506f525e79a05bbcb3   \n",
       "...       ...                               ...   \n",
       "75355   23226  10fbf670bb017ec94ebb593f0d0b4581   \n",
       "75356   23213  bae518da1e709e83596f70d1d7edd4bc   \n",
       "75357   23185  bae518da1e709e83596f70d1d7edd4bc   \n",
       "75358   23159   1ef6c2b9d413fb7c681404257d94ad9   \n",
       "75359   23142  171a3677999c79b32c8109e73b98d509   \n",
       "\n",
       "                                             description category  \\\n",
       "0      the table is round and has 3 legs. the table i...    Table   \n",
       "1      the chair is made of plastic and has 4 legs, i...    Chair   \n",
       "2      It is narrow console table.It is made from ply...    Table   \n",
       "3      A simple chair with wooden back rest and seati...    Chair   \n",
       "4      It is simple chiar with comfortable back rest ...    Chair   \n",
       "...                                                  ...      ...   \n",
       "75355                   A tall table used for decoration    Table   \n",
       "75356  Confortable and adjustable chair probably made...    Chair   \n",
       "75357  The chair is unique and adjustable.  There is ...    Chair   \n",
       "75358  Wooden table with four legs and a centerpiece ...    Table   \n",
       "75359           Nice long table to fit the whole family.    Table   \n",
       "\n",
       "       topLevelSynsetId  subSynsetId  \n",
       "0               4379243      4379243  \n",
       "1               3001627      4331277  \n",
       "2               4379243      3092883  \n",
       "3               3001627     20000020  \n",
       "4               3001627     20000020  \n",
       "...                 ...          ...  \n",
       "75355           4379243      3092883  \n",
       "75356           3001627      4373704  \n",
       "75357           3001627      4373704  \n",
       "75358           4379243      4379243  \n",
       "75359           4379243      4379243  \n",
       "\n",
       "[75358 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:20.449846300Z",
     "start_time": "2023-07-12T23:13:20.346341600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 0\n",
    "for c in captions['description'].values:\n",
    "    cur = len(c.split(\" \"))\n",
    "    if cur>max_length:\n",
    "        max_length =cur\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52499\n"
     ]
    }
   ],
   "source": [
    "train_captions=[]\n",
    "for index, row in captions.iterrows():\n",
    "    try:\n",
    "        if row[\"category\"]==\"Table\":\n",
    "            if tables_split_dict[row[\"modelId\"]]=='train':\n",
    "                train_captions.append(row['description'])\n",
    "        if row[\"category\"]==\"Chair\":\n",
    "            if chairs_split_dict[row[\"modelId\"]]=='train':\n",
    "                train_captions.append(row['description'])\n",
    "    except KeyError:\n",
    "        continue\n",
    "print(len(train_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:21.598342800Z",
     "start_time": "2023-07-12T23:13:20.449846300Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(train_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:21.613926100Z",
     "start_time": "2023-07-12T23:13:21.598342800Z"
    }
   },
   "outputs": [],
   "source": [
    "def text2shape(paths, captions, tokenizer):\n",
    "    for path in paths:\n",
    "        # with open(path, 'rb') as obj_file:\n",
    "        mesh_dict = data_utils.load_process_mesh(path)\n",
    "#         mesh_dict['class_label'] = 18 if cls==\"Chair\" else 49\n",
    "        if len(mesh_dict['faces'])>2600:\n",
    "            continue\n",
    "        try:\n",
    "            text = captions[captions[\"modelId\"]==path.split(\"/\")[-1].replace(\".obj\", \"\")].sample(n=1)[\"description\"].values[0]\n",
    "        except:\n",
    "            continue\n",
    "        text = text.lower().replace(\"the\", '').replace(\"a\", '').replace(\"of\", '').replace(\"for\", '').replace(\"and\", '').replace(\"to\", '').replace(\"in\", '')\n",
    "        text = tokenizer.texts_to_sequences([text])[0]\n",
    "        mesh_dict['text_feature'] = np.pad(text, (0,max_length-len(text)))\n",
    "        yield mesh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:21.660455100Z",
     "start_time": "2023-07-12T23:13:21.613926100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vertices': <tf.Tensor 'IteratorGetNext:2' shape=(?, 3) dtype=int32>,\n",
       " 'faces': <tf.Tensor 'IteratorGetNext:0' shape=(?,) dtype=int32>,\n",
       " 'text_feature': <tf.Tensor 'IteratorGetNext:1' shape=(140,) dtype=int32>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text2ShapeDataset = tf.data.Dataset.from_generator(\n",
    "        lambda:text2shape(train_paths, captions, tk),\n",
    "        output_types={\n",
    "            'vertices': tf.int32, 'faces': tf.int32,\n",
    "#             'class_label': tf.int32,\n",
    "            'text_feature': tf.int32},\n",
    "        output_shapes={\n",
    "            'vertices': tf.TensorShape([None, 3]), 'faces': tf.TensorShape([None]),\n",
    "#             'class_label': tf.TensorShape(()),\n",
    "            'text_feature':tf.TensorShape(140)})\n",
    "ex = Text2ShapeDataset.make_one_shot_iterator().get_next()\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:21.906000800Z",
     "start_time": "2023-07-12T23:13:21.706445600Z"
    }
   },
   "outputs": [],
   "source": [
    "vertex_model_dataset = data_utils.make_vertex_model_dataset(\n",
    "    Text2ShapeDataset, apply_random_shift=False)\n",
    "vertex_model_dataset = vertex_model_dataset.repeat()\n",
    "vertex_model_dataset = vertex_model_dataset.padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=vertex_model_dataset.output_shapes)\n",
    "vertex_model_dataset = vertex_model_dataset.prefetch(1)\n",
    "it = vertex_model_dataset.make_initializable_iterator()\n",
    "vertex_model_batch = it.get_next()\n",
    "iterator_init_op_train = it.initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text2ShapeDatasetVal = tf.data.Dataset.from_generator(\n",
    "        lambda:text2shape(val_paths, captions, tk),\n",
    "        output_types={\n",
    "            'vertices': tf.int32, 'faces': tf.int32,\n",
    "#             'class_label': tf.int32,\n",
    "            'text_feature': tf.int32},\n",
    "        output_shapes={\n",
    "            'vertices': tf.TensorShape([None, 3]), 'faces': tf.TensorShape([None]),\n",
    "#             'class_label': tf.TensorShape(()),\n",
    "            'text_feature':tf.TensorShape(140)})\n",
    "vertex_model_dataset_val = data_utils.make_vertex_model_dataset(\n",
    "    Text2ShapeDatasetVal, apply_random_shift=False)\n",
    "vertex_model_dataset_val = vertex_model_dataset_val.repeat()\n",
    "vertex_model_dataset_val = vertex_model_dataset_val.padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=vertex_model_dataset_val.output_shapes)\n",
    "vertex_model_dataset_val = vertex_model_dataset_val.prefetch(1)\n",
    "itv = vertex_model_dataset_val.make_initializable_iterator()\n",
    "vertex_model_batch_val = itv.get_next()\n",
    "iterator_init_op_val = itv.initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:21.753159Z",
     "start_time": "2023-07-12T23:13:21.680373500Z"
    }
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     ex_np = sess.run(ex)\n",
    "# print(ex_np)\n",
    "\n",
    "# # Plot the meshes\n",
    "# mesh_list = []\n",
    "# with tf.Session() as sess:\n",
    "#     for i in range(8):\n",
    "#         ex_np = sess.run(ex)\n",
    "#         mesh_list.append(\n",
    "#         {'vertices': data_utils.dequantize_verts(ex_np['vertices']),\n",
    "#          'faces': data_utils.unflatten_faces(ex_np['faces'])})\n",
    "# data_utils.plot_meshes(mesh_list, ax_lims=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:39.111517Z",
     "start_time": "2023-07-12T23:13:21.906000800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917494 word vectors.\n",
      "Converted 8256 words (1212 misses)\n"
     ]
    }
   ],
   "source": [
    "vertex_model = modules.TextToVertexModel(\n",
    "    decoder_config=dict(\n",
    "      hidden_size=512,\n",
    "      fc_size=2048,\n",
    "      num_heads=8,\n",
    "      layer_norm=True,\n",
    "      num_layers=24,\n",
    "      dropout_rate=0.4,\n",
    "      re_zero=True,\n",
    "      memory_efficient=True\n",
    "      ),\n",
    "    path_to_embeddings=\"glove.42B.300d.txt\",\n",
    "    embedding_dims = 300,\n",
    "    quantization_bits=8,\n",
    "    tokenizer=tk,\n",
    "    max_num_input_verts=5000,  # number of vertices in the input mesh, if this is lower than the number of vertices in the mesh, there will be errors during training\n",
    "    use_discrete_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.650342600Z",
     "start_time": "2023-07-12T23:13:39.111517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vertices': <tf.Tensor 'IteratorGetNext_1:2' shape=(?, ?, 3) dtype=int32>, 'faces': <tf.Tensor 'IteratorGetNext_1:0' shape=(?, ?) dtype=int32>, 'text_feature': <tf.Tensor 'IteratorGetNext_1:1' shape=(?, 140) dtype=int32>, 'vertices_flat': <tf.Tensor 'IteratorGetNext_1:3' shape=(?, ?) dtype=int32>, 'vertices_flat_mask': <tf.Tensor 'IteratorGetNext_1:4' shape=(?, ?) dtype=float32>}\n",
      "tfp.distributions.Categorical(\"vertex_model_2/vertex_model/create_dist/Categorical/\", batch_shape=[?, ?], event_shape=[], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "vertex_model_pred_dist = vertex_model(vertex_model_batch)\n",
    "vertex_model_loss = -tf.reduce_sum(\n",
    "    vertex_model_pred_dist.log_prob(vertex_model_batch['vertices_flat']) *\n",
    "    vertex_model_batch['vertices_flat_mask'])\n",
    "vertex_samples = vertex_model.sample(\n",
    "    BATCH_SIZE, context=vertex_model_batch, max_sample_length=1000, top_p=0.95,\n",
    "    recenter_verts=False, only_return_complete=False)\n",
    "\n",
    "print(vertex_model_batch)\n",
    "print(vertex_model_pred_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_model_pred_dist_val = vertex_model(vertex_model_batch_val)\n",
    "vertex_model_loss_val = -tf.reduce_sum(\n",
    "    vertex_model_pred_dist_val.log_prob(vertex_model_batch_val['vertices_flat']) *\n",
    "    vertex_model_batch_val['vertices_flat_mask'])\n",
    "vertex_samples_val = vertex_model.sample(\n",
    "    BATCH_SIZE, context=vertex_model_batch_val, max_sample_length=1000, top_p=0.95,\n",
    "    recenter_verts=False, only_return_complete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.713110300Z",
     "start_time": "2023-07-12T23:13:57.650342600Z"
    }
   },
   "outputs": [],
   "source": [
    "# vertex_module_config=dict(\n",
    "#   decoder_config=dict(\n",
    "#       hidden_size=512,\n",
    "#       fc_size=2048,\n",
    "#       num_heads=8,\n",
    "#       layer_norm=True,\n",
    "#       num_layers=24,\n",
    "#       dropout_rate=0.4,\n",
    "#       re_zero=True,\n",
    "#       memory_efficient=True\n",
    "#       ),\n",
    "#   quantization_bits=8,\n",
    "#   class_conditional=True,\n",
    "#   max_num_input_verts=5000,\n",
    "#   use_discrete_embeddings=True,\n",
    "#   )\n",
    "# vertex_model1 = modules.VertexModel(**vertex_module_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.747046Z",
     "start_time": "2023-07-12T23:13:57.665967200Z"
    }
   },
   "outputs": [],
   "source": [
    "# vertex_model_pred_dist = vertex_model(vertex_model_batch)\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     text_vars = vertex_model.variables\n",
    "# print(text_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.762667100Z",
     "start_time": "2023-07-12T23:13:57.713110300Z"
    }
   },
   "outputs": [],
   "source": [
    "# vertex_model1_pred_dist = vertex_model1(vertex_model_batch)\n",
    "# with tf.Session() as sess:\n",
    "#     orig_vars = vertex_model1.variables\n",
    "# print(orig_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.762667100Z",
     "start_time": "2023-07-12T23:13:57.713110300Z"
    }
   },
   "outputs": [],
   "source": [
    "# text_vars_names = []\n",
    "# for v in text_vars:\n",
    "# #     shape = tuple()\n",
    "# #     for dim in v._variable._shape_val._dims:\n",
    "# #         shape = shape+(dim._value,)\n",
    "# #     text_vars_names.append(('/'.join((v._variable._name).split('/')[1:]), shape))\n",
    "#     text_vars_names.append('/'.join((v._variable._name).split('/')[1:]))\n",
    "# print(text_vars_names)\n",
    "\n",
    "#'coord_embeddings/embeddings:0', 'coord_embeddings_1/embeddings:0', 'embed/embeddings:0', 'embed_zero:0', 'linear/b:0', 'linear/w:0', 'linear_1/b:0', 'linear_1/w:0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.794703100Z",
     "start_time": "2023-07-12T23:13:57.747046Z"
    }
   },
   "outputs": [],
   "source": [
    "# orig_vars_names = []\n",
    "# for v in orig_vars:\n",
    "# #     shape = tuple()\n",
    "# #     for dim in v._variable._shape_val._dims:\n",
    "# #         shape = shape+(dim._value,)\n",
    "# #     orig_vars_names.append(('/'.join((v._variable._name).split('/')[1:]), shape))\n",
    "#     orig_vars_names.append('/'.join((v._variable._name).split('/')[1:]))\n",
    "# print(orig_vars_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.794703100Z",
     "start_time": "2023-07-12T23:13:57.747046Z"
    }
   },
   "outputs": [],
   "source": [
    "# common_vars = set(text_vars_names) & set(orig_vars_names)\n",
    "# print(common_vars)\n",
    "# only_text_vars = set(text_vars_names) - common_vars\n",
    "# print(only_text_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_text_vars = set(text_vars_names) - common_vars\n",
    "# print(only_text_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(orig_vars_names) - common_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.794703100Z",
     "start_time": "2023-07-12T23:13:57.762667100Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"only_text_vars.pickle\", 'wb') as out:\n",
    "#     pickle.dump(only_text_vars, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"only_text_vars.pickle\", 'rb') as f:\n",
    "    only_text_vars = pickle.load(f)\n",
    "\n",
    "text_vars = []\n",
    "for var in vertex_model.variables:\n",
    "    if '/'.join((var._variable._name).split('/')[1:]) in only_text_vars:\n",
    "        text_vars.append(var)\n",
    "text_vars=tuple(text_vars)\n",
    "# print(text_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.794703100Z",
     "start_time": "2023-07-12T23:13:57.779077200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"pretrained_vars.pickle\", 'rb') as f:\n",
    "    common_vars = pickle.load(f)\n",
    "\n",
    "pretrained_vars = []\n",
    "for var in vertex_model.variables:\n",
    "    if '/'.join((var._variable._name).split('/')[1:]) in common_vars:\n",
    "        pretrained_vars.append(var)\n",
    "pretrained_vars=tuple(pretrained_vars)\n",
    "# print(pretrained_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.810357600Z",
     "start_time": "2023-07-12T23:13:57.794703100Z"
    }
   },
   "outputs": [],
   "source": [
    "vertex_model_saver = tf.train.Saver(var_list=pretrained_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:13:57.841566200Z",
     "start_time": "2023-07-12T23:13:57.810357600Z"
    }
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#   vertex_model_saver.restore(sess, \"D:\\\\PyCharmProjects\\\\vertex_model\\\\model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:14:13.344725100Z",
     "start_time": "2023-07-12T23:13:57.825948300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vertices': <tf.Tensor 'IteratorGetNext_3:4' shape=(?, ?, 3) dtype=float32>, 'faces': <tf.Tensor 'IteratorGetNext_3:0' shape=(?, ?) dtype=int64>, 'text_feature': <tf.Tensor 'IteratorGetNext_3:3' shape=(?, 140) dtype=int32>, 'num_vertices': <tf.Tensor 'IteratorGetNext_3:2' shape=(?,) dtype=int32>, 'vertices_mask': <tf.Tensor 'IteratorGetNext_3:5' shape=(?, ?) dtype=float32>, 'faces_mask': <tf.Tensor 'IteratorGetNext_3:1' shape=(?, ?) dtype=float32>}\n",
      "tfp.distributions.Categorical(\"face_model_1/face_model/create_dist/Categorical/\", batch_shape=[?, ?], event_shape=[], dtype=int32)\n",
      "{'context': {'completed': <tf.Tensor 'Any:0' shape=(?,) dtype=bool>, 'vertices': <tf.Tensor 'mul_4:0' shape=(?, 1000, 3) dtype=float32>, 'num_vertices': <tf.Tensor 'floordiv:0' shape=(?,) dtype=int32>, 'vertices_mask': <tf.Tensor 'Cast_2:0' shape=(?, 1000) dtype=float32>}, 'completed': <tf.Tensor 'Any_2:0' shape=(?,) dtype=bool>, 'faces': <tf.Tensor 'Pad_2:0' shape=(?, ?) dtype=int32>, 'num_face_indices': <tf.Tensor 'add_2:0' shape=(?,) dtype=int32>}\n"
     ]
    }
   ],
   "source": [
    "face_model_dataset = data_utils.make_face_model_dataset(\n",
    "    Text2ShapeDataset, apply_random_shift=False)\n",
    "face_model_dataset = face_model_dataset.repeat()\n",
    "face_model_dataset = face_model_dataset.padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=face_model_dataset.output_shapes)\n",
    "face_model_dataset = face_model_dataset.prefetch(1)\n",
    "face_model_batch = face_model_dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "# Create face model\n",
    "face_model = modules.FaceModel(\n",
    "      encoder_config=dict(\n",
    "      hidden_size=512,\n",
    "      fc_size=2048,\n",
    "      num_heads=8,\n",
    "      layer_norm=True,\n",
    "      num_layers=10,\n",
    "      dropout_rate=0.2,\n",
    "      re_zero=True,\n",
    "      memory_efficient=True,\n",
    "      ),\n",
    "  decoder_config=dict(\n",
    "      hidden_size=512,\n",
    "      fc_size=2048,\n",
    "      num_heads=8,\n",
    "      layer_norm=True,\n",
    "      num_layers=14,\n",
    "      dropout_rate=0.2,\n",
    "      re_zero=True,\n",
    "      memory_efficient=True,\n",
    "      ),\n",
    "    class_conditional=False,\n",
    "    max_seq_length=8000, # number of faces in the input mesh, if this is lower than the number of vertices in the mesh, there will be errors during training\n",
    "    quantization_bits=8,\n",
    "    decoder_cross_attention=True,\n",
    "    use_discrete_vertex_embeddings=True,\n",
    ")\n",
    "face_model_pred_dist = face_model(face_model_batch)\n",
    "face_model_loss = -tf.reduce_sum(\n",
    "    face_model_pred_dist.log_prob(face_model_batch['faces']) *\n",
    "    face_model_batch['faces_mask'])\n",
    "face_samples = face_model.sample(\n",
    "    context=vertex_samples, max_sample_length=1000, top_p=0.95,\n",
    "    only_return_complete=False)\n",
    "print(face_model_batch)\n",
    "print(face_model_pred_dist)\n",
    "print(face_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_model_dataset_val = data_utils.make_face_model_dataset(\n",
    "    Text2ShapeDatasetVal, apply_random_shift=False)\n",
    "face_model_dataset_val  = face_model_dataset_val .repeat()\n",
    "face_model_dataset_val  = face_model_dataset_val .padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=face_model_dataset_val.output_shapes)\n",
    "face_model_dataset_val = face_model_dataset_val.prefetch(1)\n",
    "face_model_batch_val = face_model_dataset_val.make_one_shot_iterator().get_next()\n",
    "\n",
    "face_samples_val = face_model.sample(\n",
    "    context=vertex_samples_val, max_sample_length=1000, top_p=0.95,\n",
    "    only_return_complete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:14:13.360755400Z",
     "start_time": "2023-07-12T23:14:13.344725100Z"
    }
   },
   "outputs": [],
   "source": [
    "face_model_saver = tf.train.Saver(var_list=face_model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T23:14:13.407246600Z",
     "start_time": "2023-07-12T23:14:13.360755400Z"
    }
   },
   "outputs": [],
   "source": [
    "text_model_saver = tf.train.Saver(var_list=vertex_model.variables, keep_checkpoint_every_n_hours=1, max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 23:28:30.020799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-07-17 23:28:30.075142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1669] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3090 major: 8 minor: 6 memoryClockRate(GHz): 1.74\n",
      "pciBusID: 0000:65:00.0\n",
      "2023-07-17 23:28:30.075180: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-07-17 23:28:30.347692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-07-17 23:28:30.354709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-17 23:28:30.356745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-17 23:28:30.359521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-07-17 23:28:30.363277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-07-17 23:28:30.364592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-07-17 23:28:30.365220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1797] Adding visible gpu devices: 0\n",
      "2023-07-17 23:28:30.494442: I tensorflow/core/platform/profile_utils/cpu_utils.cc:109] CPU Frequency: 3899935000 Hz\n",
      "2023-07-17 23:28:30.496046: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x84fc4ec0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-17 23:28:30.496087: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-07-17 23:28:30.587142: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x9693e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-17 23:28:30.587186: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-07-17 23:28:30.587746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1669] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3090 major: 8 minor: 6 memoryClockRate(GHz): 1.74\n",
      "pciBusID: 0000:65:00.0\n",
      "2023-07-17 23:28:30.587817: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-07-17 23:28:30.587867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-07-17 23:28:30.587892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-17 23:28:30.587915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-17 23:28:30.587938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-07-17 23:28:30.587962: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-07-17 23:28:30.587994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-07-17 23:28:30.588531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1797] Adding visible gpu devices: 0\n",
      "2023-07-17 23:28:30.588591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-07-17 23:28:32.567645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1209] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-07-17 23:28:32.567705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1215]      0 \n",
      "2023-07-17 23:28:32.567719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1228] 0:   N \n",
      "2023-07-17 23:28:32.568679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1354] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22054 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                 | 0/5 [00:00<?, ?it/s]2023-07-17 23:29:56.104306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "/cluster/51/ala1s/deepmind-research/polygen/data_utils.py:162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(vertices), np.array(faces)\n",
      "2023-07-17 23:29:58.389495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 5/5 [01:37<00:00, 19.53s/it, loss=291.046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train metrics: loss: 571.653\n",
      "- Eval metrics: loss: 562.831\n",
      "- Found new best model, saving in text_generaization/best-1\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                 | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "import os\n",
    "\n",
    "with tf.variable_scope(\"metrics\"):\n",
    "    metrics = {\n",
    "            'loss': tf.metrics.mean(vertex_model_loss),\n",
    "            }\n",
    "update_metrics_op = tf.group(*[op for _, op in metrics.values()])\n",
    "metric_variables = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=\"metrics\")\n",
    "metrics_init_op = tf.variables_initializer(metric_variables)\n",
    "\n",
    "tf.summary.scalar('loss', vertex_model_loss)\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "\n",
    "# text_model_saver = tf.train.Saver(var_list=vertex_model.variables, keep_checkpoint_every_n_hours=1, max_to_keep=10)\n",
    "last_saver = tf.train.Saver(var_list=vertex_model.variables) # will keep last 5 epochs\n",
    "best_saver = tf.train.Saver(var_list=vertex_model.variables, max_to_keep=2)  # only keep 1 best checkpoint (best on eval)\n",
    "\n",
    "%matplotlib inline \n",
    "learning_rate = 5e-4\n",
    "training_steps = 500\n",
    "check_step_metrics = 10\n",
    "check_step_samples = 100\n",
    "EPOCHS = 20\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "vertex_model_optim_op = optimizer.minimize(vertex_model_loss, var_list=text_vars)\n",
    "best_v_loss = float('inf')\n",
    "# Training loop\n",
    "global_step = tf.train.create_global_step()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    vertex_model_saver.restore(sess, \"vertex_model/model\")\n",
    "    face_model_saver.restore(sess, 'face_model/model')\n",
    "    \n",
    "    train_writer = s.FileWriter(os.path.join(log_dir, 'train_summaries'), sess.graph)\n",
    "    eval_writer = s.FileWriter(os.path.join(log_dir, 'eval_summaries'), sess.graph)\n",
    "    \n",
    "    for e in range(EPOCHS):\n",
    "        print(\"Epoch {}/{}\".format(e + 1, EPOCHS))\n",
    "        num_steps = (TRAIN_SIZE + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "        global_step = tf.train.get_global_step()\n",
    "        sess.run(iterator_init_op_train)\n",
    "        sess.run(metrics_init_op)\n",
    "        t = trange(num_steps)\n",
    "        for i in t:\n",
    "            \n",
    "            #fhjghvkerl\n",
    "            if i % check_step_metrics == 0:\n",
    "                _, _, loss_val, summ, global_step_val = sess.run([vertex_model_optim_op, update_metrics_op, vertex_model_loss,\n",
    "                                                              summary_op, global_step])\n",
    "                #_, _, loss_val, global_step_val = sess.run([vertex_model_optim_op, update_metrics_op, vertex_model_loss, global_step])\n",
    "#                 sess.run(vertex_model_optim_op)\n",
    "#                 sess.run(update_metrics_op)\n",
    "#                 loss_val = sess.run(vertex_model_loss)\n",
    "#                 global_step_val = sess.run(global_step)\n",
    "                train_writer.add_summary(summ, global_step_val)\n",
    "            else:\n",
    "                _, _, loss_val = sess.run([vertex_model_optim_op, update_metrics_op, vertex_model_loss])\n",
    "            # Log the loss in the tqdm progress bar\n",
    "            t.set_postfix(loss='{:05.3f}'.format(loss_val))\n",
    "        metrics_values = {k: v[0] for k, v in metrics.items()}\n",
    "        metrics_val = sess.run(metrics_values)\n",
    "        metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_val.items())\n",
    "        print(\"- Train metrics: \" + metrics_string)\n",
    "        \n",
    "        last_save_path = os.path.join(\"text_generaization\", 'last')\n",
    "        last_saver.save(sess, last_save_path, global_step=e + 1)\n",
    "    \n",
    "        num_steps = (VAL_SIZE + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "        eval_metrics = metrics\n",
    "        sess.run(iterator_init_op_val)\n",
    "        sess.run(metrics_init_op)\n",
    "        for _ in range(num_steps):\n",
    "            sess.run(update_metrics_op)\n",
    "        metrics_values = {k: v[0] for k, v in eval_metrics.items()}\n",
    "        metrics_val = sess.run(metrics_values)\n",
    "        metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v) for k, v in metrics_val.items())\n",
    "        print(\"- Eval metrics: \" + metrics_string)\n",
    "        global_step_val = sess.run(global_step)\n",
    "        for tag, val in metrics_val.items():\n",
    "            summ = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=val)])\n",
    "            eval_writer.add_summary(summ, global_step_val)\n",
    "        \n",
    "        if metrics_val['loss']<=best_v_loss:\n",
    "            best_v_loss = metrics_val['loss']\n",
    "            best_save_path = os.path.join('text_generaization', 'best')\n",
    "            best_save_path = best_saver.save(sess, best_save_path, global_step=e + 1)\n",
    "            print(\"- Found new best model, saving in {}\".format(best_save_path))\n",
    "                \n",
    "#         #SAmples\n",
    "#         if e>2:\n",
    "#             sess.run(iterator_init_op_val)\n",
    "#             v_samples_np, f_samples_np, b_np = sess.run((vertex_samples_val, face_samples_val, vertex_model_batch_val))\n",
    "#             mesh_list = []\n",
    "#             for n in range(BATCH_SIZE):\n",
    "#                 mesh_list.append({\n",
    "#                     'vertices': v_samples_np['vertices'][n][:v_samples_np['num_vertices'][n]],\n",
    "#                     'faces': data_utils.unflatten_faces(\n",
    "#                         f_samples_np['faces'][n][:f_samples_np['num_face_indices'][n]])\n",
    "#                     })\n",
    "#             data_utils.plot_meshes(mesh_list, ax_lims=0.5)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in metrics.items():\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-12T23:27:56.171310400Z"
    },
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# %matplotlib inline \n",
    "# learning_rate = 5e-4\n",
    "# training_steps = 1500\n",
    "# check_step_metrics = 10\n",
    "# check_step_samples = 300\n",
    "\n",
    "# # Create an optimizer an minimize the summed log probability of the mesh\n",
    "# # sequences\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# vertex_model_optim_op = optimizer.minimize(vertex_model_loss, var_list=text_vars)\n",
    "# best_v_loss = float('inf')\n",
    "# # Training loop\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     vertex_model_saver.restore(sess, \"vertex_model/model\")\n",
    "#     face_model_saver.restore(sess, 'face_model/model')\n",
    "#     for i in range(training_steps):\n",
    "#         if i % check_step_metrics == 0:\n",
    "#             v_loss_train = sess.run(vertex_model_loss)\n",
    "# #             with summary_writer:\n",
    "# #                 tf.summary.scalar('vertex_loss_train', v_loss_train)\n",
    "#             v_loss_val = sess.run(vertex_model_loss_val)\n",
    "# #             with summary_writer:\n",
    "# #                 tf.summary.scalar('vertex_loss_val', v_loss_val)\n",
    "#             if v_loss_val<best_v_loss:\n",
    "#                 text_model_saver.save(sess, 'text_model/', global_step=i)\n",
    "#                 best_v_loss = v_loss_val\n",
    "#                 print(\"saved best model\")\n",
    "        \n",
    "#             print('Step {}'.format(i))\n",
    "#             print('Loss vertices train {}'.format(v_loss_train))\n",
    "#             print('Loss vertices val {}'.format(v_loss_val))\n",
    "#         if i % check_step_samples == 0:\n",
    "#             v_samples_np, f_samples_np, b_np = sess.run((vertex_samples_val, face_samples_val, vertex_model_batch_val))\n",
    "#             mesh_list = []\n",
    "#             for n in range(BATCH_SIZE):\n",
    "#                 mesh_list.append({\n",
    "#                 'vertices': v_samples_np['vertices'][n][:v_samples_np['num_vertices'][n]],\n",
    "#                 'faces': data_utils.unflatten_faces(\n",
    "#                     f_samples_np['faces'][n][:f_samples_np['num_face_indices'][n]])\n",
    "#                 })\n",
    "#             data_utils.plot_meshes(mesh_list, ax_lims=0.5)\n",
    "#         sess.run(vertex_model_optim_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-09T22:40:37.817788600Z",
     "start_time": "2023-07-09T22:40:37.403853900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-09T22:40:37.820785600Z",
     "start_time": "2023-07-09T22:40:37.525527600Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-09T22:40:37.821779300Z",
     "start_time": "2023-07-09T22:40:37.527522Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-09T22:40:37.857167300Z",
     "start_time": "2023-07-09T22:40:37.608351800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last1",
   "language": "python",
   "name": "last1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
