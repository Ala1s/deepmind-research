{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szgmaK1HajOc"
   },
   "source": [
    "Copyright 2020 DeepMind Technologies Limited\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_dv0afOrKheU"
   },
   "source": [
    "## Clone repo and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T21:20:38.367141800Z",
     "start_time": "2023-07-04T21:19:43.323971600Z"
    }
   },
   "outputs": [],
   "source": [
    "# import objaverse\n",
    "# import multiprocessing\n",
    "# import random\n",
    "import trimesh\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "#\n",
    "# processes = multiprocessing.cpu_count()\n",
    "# random.seed(42)\n",
    "# uids = objaverse.load_uids()\n",
    "# random_object_uids = random.sample(uids, 4)\n",
    "# objects = objaverse.load_objects(\n",
    "#     uids=random_object_uids,\n",
    "#     download_processes=processes\n",
    "# )\n",
    "\n",
    "# chair_meshes_paths = glob(\"D:\\\\ShapeNetCore.v2\\\\03001627\\\\*\\\\models\\\\model_normalized.obj\")\n",
    "# table_meshes_path = glob(\"D:\\\\ShapeNetCore.v2\\\\04379243\\\\*\\\\models\\\\model_normalized.obj\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8436/8436 [03:36<00:00, 38.91it/s]\n"
     ]
    }
   ],
   "source": [
    "good_meshes = []\n",
    "for path in tqdm(table_meshes_path):\n",
    "    with open(path, 'r') as obj_file:\n",
    "        count=0\n",
    "        lines = obj_file.readlines()\n",
    "        for line in lines:\n",
    "            if line.split(\" \")[0]==\"v\":\n",
    "                count+=1\n",
    "    if count < 800:\n",
    "        good_meshes.append(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T21:24:49.402243Z",
     "start_time": "2023-07-04T21:21:12.588964400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "5522"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_meshes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T21:24:49.436049200Z",
     "start_time": "2023-07-04T21:24:49.402243Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5522/5522 [00:05<00:00, 1076.16it/s]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "for path in tqdm(good_meshes):\n",
    "    dst = \"C:\\\\Users\\\\babic\\\\PycharmProjects\\\\deepmind-research\\\\polygen\\\\data\\\\tables\\\\\" + path.replace(\"D:\\\\ShapeNetCore.v2\\\\04379243\\\\\", '').replace(\"\\\\models\\\\model_normalized\", '')\n",
    "    shutil.copyfile(path, dst)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-04T21:26:12.364194800Z",
     "start_time": "2023-07-04T21:26:07.216633700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# for path in tqdm(chair_meshes_paths):\n",
    "#     with open(path, 'r') as obj_file:\n",
    "#         lines = obj_file.readlines()\n",
    "#         new_lines = []\n",
    "#         for line in lines:\n",
    "#             if line.split(\" \")[0]==\"v\":\n",
    "#                 new_lines.append(line)\n",
    "#             elif line.split(\" \")[0]==\"f\":\n",
    "#                 new_lines.append(line)\n",
    "#         with open(path.replace(\"model_normalized\", \"clean\"), 'w') as obj_file2:\n",
    "#             obj_file2.writelines(new_lines)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T13:28:47.121642500Z",
     "start_time": "2023-07-03T13:28:47.118650300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# chair_meshes_paths_clean = glob(\"D:\\\\ShapeNetCore.v2\\\\03001627\\\\*\\\\models\\\\clean.obj\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T13:28:47.122641700Z",
     "start_time": "2023-07-03T13:28:47.119649Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ux33ZDQ_tqUV",
    "ExecuteTime": {
     "end_time": "2023-07-03T13:28:57.238599Z",
     "start_time": "2023-07-03T13:28:47.122641700Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)  # Hide TF deprecation messages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import modules\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2166/6778 [33:18<1:10:54,  1.08it/s] \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 50.2 GiB for an array with shape (63483, 849432) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9236\\3531445838.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mpath\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mchair_meshes_paths\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m         \u001B[0mmesh_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_process_mesh\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mIndexError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[1;32mcontinue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\deepmind-research\\polygen\\data_utils.py\u001B[0m in \u001B[0;36mload_process_mesh\u001B[1;34m(mesh_obj_path, quantization_bits)\u001B[0m\n\u001B[0;32m    357\u001B[0m     \u001B[1;31m# Load mesh\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    358\u001B[0m     \u001B[0mvertices\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfaces\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mread_obj\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmesh_obj_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 359\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mprocess_mesh\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvertices\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfaces\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mquantization_bits\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    360\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    361\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\deepmind-research\\polygen\\data_utils.py\u001B[0m in \u001B[0;36mprocess_mesh\u001B[1;34m(vertices, faces, quantization_bits)\u001B[0m\n\u001B[0;32m    323\u001B[0m     \u001B[1;31m# faces.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m     vertices, faces, _ = quantize_process_mesh(\n\u001B[1;32m--> 325\u001B[1;33m         vertices, faces, quantization_bits=quantization_bits)\n\u001B[0m\u001B[0;32m    326\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    327\u001B[0m     \u001B[1;31m# Flatten faces and add 'new face' = 1 and 'stop' = 0 tokens.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\deepmind-research\\polygen\\data_utils.py\u001B[0m in \u001B[0;36mquantize_process_mesh\u001B[1;34m(vertices, faces, tris, quantization_bits)\u001B[0m\n\u001B[0;32m    294\u001B[0m     \u001B[0mnum_verts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvertices\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    295\u001B[0m     vert_connected = np.equal(\n\u001B[1;32m--> 296\u001B[1;33m         np.arange(num_verts)[:, None], np.hstack(faces)[None]).any(axis=-1)\n\u001B[0m\u001B[0;32m    297\u001B[0m     \u001B[0mvertices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvertices\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mvert_connected\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    298\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 50.2 GiB for an array with shape (63483, 849432) and data type bool"
     ]
    }
   ],
   "source": [
    "ex_list = []\n",
    "max_verts  = 600 #800\n",
    "max_faces = 2000 #2800\n",
    "for path in tqdm(chair_meshes_paths):\n",
    "    try:\n",
    "        mesh_dict = data_utils.load_process_mesh(path)\n",
    "    except IndexError:\n",
    "        continue\n",
    "    except ValueError:\n",
    "        continue\n",
    "    if(len(mesh_dict['vertices']) > max_verts):\n",
    "         continue\n",
    "    if(len(mesh_dict['faces']) > max_faces):\n",
    "        continue\n",
    "    mesh_dict['class_label'] = 0 #18\n",
    "    ex_list.append(mesh_dict)\n",
    "    # if len(ex_list)>2:\n",
    "    #     break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T14:02:16.157605400Z",
     "start_time": "2023-07-03T13:28:57.238599Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f# def shapenet(paths):\n",
    "#     for path in paths:\n",
    "#         # with open(path, 'rb') as obj_file:\n",
    "#         scene = trimesh.load(path)\n",
    "#         if not isinstance(scene, trimesh.base.Trimesh):\n",
    "#             geometries = list(scene.geometry.values())\n",
    "#             geometry = geometries[0]\n",
    "#             yield geometry\n",
    "#         else:\n",
    "#             yield scene\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# meshes = []\n",
    "# for path in tqdm(chair_meshes_paths):\n",
    "#     # with open(path, 'rb') as obj_file:\n",
    "#     scene = trimesh.load(path)\n",
    "#     if not isinstance(scene, trimesh.base.Trimesh):\n",
    "#         geometries = list(scene.geometry.values())\n",
    "#         geometry = geometries[0]\n",
    "#         meshes.append(geometry)\n",
    "#     else:\n",
    "#         meshes.append(scene)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_list = []\n",
    "# max_verts  = 800\n",
    "# max_faces = 2800\n",
    "# for mesh in tqdm(meshes):\n",
    "#     if(mesh.vertices.shape[0] > max_verts):\n",
    "#          continue\n",
    "#     try:\n",
    "#         mesh_dict = data_utils.process_mesh_trimesh(mesh)\n",
    "#     except ValueError:\n",
    "#         continue\n",
    "#     if(len(mesh_dict['vertices']) > max_verts):\n",
    "#          continue\n",
    "#     if(len(mesh_dict['faces']) > max_faces):\n",
    "#         continue\n",
    "#     mesh_dict['faces']\n",
    "#       # print(mesh_dict['vertices'])\n",
    "#     # if(len(mesh_dict['vertices']) > max_verts):\n",
    "#     #     max_verts = len(mesh_dict['vertices'])\n",
    "#     # if(len(mesh_dict['faces']) > max_faces):\n",
    "#     #     max_faces = len(mesh_dict['faces'])\n",
    "#     mesh_dict['class_label'] = 18\n",
    "#     ex_list.append(mesh_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(ex_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex_list[1]['faces']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "p = ex_list[:2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T02:28:53.222220200Z",
     "start_time": "2023-07-03T02:28:53.207249100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "synthetic_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: ex_list,\n",
    "        output_types={\n",
    "            'vertices': tf.int32, 'faces': tf.int32, 'class_label': tf.int32},\n",
    "        output_shapes={\n",
    "            'vertices': tf.TensorShape([None, 3]), 'faces': tf.TensorShape([None]),\n",
    "            'class_label': tf.TensorShape(())}\n",
    "        )\n",
    "# print(max_verts)\n",
    "# print(max_faces)\n",
    "ex = synthetic_dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "# Inspect the first mesh\n",
    "with tf.Session() as sess:\n",
    "  ex_np = sess.run(ex)\n",
    "print(ex_np)\n",
    "\n",
    "# Plot the meshes\n",
    "mesh_list = []\n",
    "with tf.Session() as sess:\n",
    "  for i in range(4):\n",
    "    ex_np = sess.run(ex)\n",
    "    mesh_list.append(\n",
    "        {'vertices': data_utils.dequantize_verts(ex_np['vertices']),\n",
    "         'faces': data_utils.unflatten_faces(ex_np['faces'])})\n",
    "data_utils.plot_meshes(mesh_list, ax_lims=0.4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9G2FCQQyyTXw"
   },
   "source": [
    "## Vertex model\n",
    "\n",
    "#### Prepare the dataset for vertex model training\n",
    "We need to perform some additional processing to make the dataset ready for vertex model training. In particular, `data_utils.make_vertex_model_dataset` flattens the `[V, 3]` vertex arrays, ordering by `Z->Y->X` coordinates. It also creates masks, which are used to mask padded elements in data batches. We also add random shifts to make the modelling task more challenging.\n",
    "\n",
    "#### Create a vertex model\n",
    "`modules.VertexModel` is a Sonnet module that. Calling the module on a batch of data will produce outputs which are the sequential predictions for each vertex coordinate. The basis of the vertex model is a Transformer decoder, and we specify it's parameters in `decoder_config`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2KCoDeeFP8C"
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset for vertex model training\n",
    "vertex_model_dataset = data_utils.make_vertex_model_dataset(\n",
    "    synthetic_dataset, apply_random_shift=False)\n",
    "vertex_model_dataset = vertex_model_dataset.repeat()\n",
    "vertex_model_dataset = vertex_model_dataset.padded_batch(\n",
    "    1, padded_shapes=vertex_model_dataset.output_shapes)\n",
    "vertex_model_dataset = vertex_model_dataset.prefetch(1)\n",
    "vertex_model_batch = vertex_model_dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "# Create vertex model\n",
    "vertex_model = modules.VertexModel(\n",
    "    decoder_config={\n",
    "        'hidden_size': 128,\n",
    "        'fc_size': 512, \n",
    "        'num_layers': 3,\n",
    "        'dropout_rate': 0.\n",
    "    },\n",
    "    class_conditional=True,\n",
    "    num_classes=1,\n",
    "    max_num_input_verts=max_verts ,  # number of vertices in the input mesh, if this is lower than the number of vertices in the mesh, there will be errors during training\n",
    "    quantization_bits=8,\n",
    ")\n",
    "vertex_model_pred_dist = vertex_model(vertex_model_batch)\n",
    "vertex_model_loss = -tf.reduce_sum(\n",
    "    vertex_model_pred_dist.log_prob(vertex_model_batch['vertices_flat']) * \n",
    "    vertex_model_batch['vertices_flat_mask'])\n",
    "vertex_samples = vertex_model.sample(\n",
    "    1, context=vertex_model_batch, max_sample_length=1500, top_p=0.95,\n",
    "    recenter_verts=False, only_return_complete=False)\n",
    "\n",
    "print(vertex_model_batch)\n",
    "print(vertex_model_pred_dist)\n",
    "print(vertex_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9RNYr5x1jov"
   },
   "source": [
    "## Face model\n",
    "\n",
    "#### Prepare the dataset for face model training\n",
    "We need to perform some additional processing to make the dataset ready for vertex model training. In particular, `data_utils.make_vertex_model_dataset` flattens the `[V, 3]` vertex arrays, ordering by `Z->Y->X` coordinates. It also creates masks, which are used to mask padded elements in data batches. We also add random shifts to make the modelling task more challenging.\n",
    "\n",
    "#### Create a face model\n",
    "`modules.VertexModel` is a Sonnet module that. Calling the module on a batch of data will produce outputs which are the sequential predictions for each vertex coordinate. The basis of the vertex model is a Transformer decoder, and we specify it's parameters in `decoder_config`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2yO6dOGzn8c"
   },
   "outputs": [],
   "source": [
    "face_model_dataset = data_utils.make_face_model_dataset(\n",
    "    synthetic_dataset, apply_random_shift=False)\n",
    "face_model_dataset = face_model_dataset.repeat()\n",
    "face_model_dataset = face_model_dataset.padded_batch(\n",
    "    1, padded_shapes=face_model_dataset.output_shapes)\n",
    "face_model_dataset = face_model_dataset.prefetch(1)\n",
    "face_model_batch = face_model_dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "# Create face model\n",
    "face_model = modules.FaceModel(\n",
    "    encoder_config={\n",
    "        'hidden_size': 128,\n",
    "        'fc_size': 512, \n",
    "        'num_layers': 3,\n",
    "        'dropout_rate': 0.\n",
    "    },\n",
    "    decoder_config={\n",
    "        'hidden_size': 128,\n",
    "        'fc_size': 512, \n",
    "        'num_layers': 3,\n",
    "        'dropout_rate': 0.\n",
    "    },\n",
    "    class_conditional=False,\n",
    "    max_seq_length=max_faces, # number of faces in the input mesh, if this is lower than the number of vertices in the mesh, there will be errors during training\n",
    "    quantization_bits=8,\n",
    "    decoder_cross_attention=True,\n",
    "    use_discrete_vertex_embeddings=True,\n",
    ")\n",
    "face_model_pred_dist = face_model(face_model_batch)\n",
    "face_model_loss = -tf.reduce_sum(\n",
    "    face_model_pred_dist.log_prob(face_model_batch['faces']) * \n",
    "    face_model_batch['faces_mask'])\n",
    "face_samples = face_model.sample(\n",
    "    context=vertex_samples, max_sample_length=1500, top_p=0.95,\n",
    "    only_return_complete=False)\n",
    "print(face_model_batch)\n",
    "print(face_model_pred_dist)\n",
    "print(face_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjrbofa8zqQt"
   },
   "outputs": [],
   "source": [
    "# Optimization settings\n",
    "learning_rate = 5e-4\n",
    "training_steps = 500*160\n",
    "check_step = 160\n",
    "\n",
    "# Create an optimizer an minimize the summed log probability of the mesh \n",
    "# sequences\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "vertex_model_optim_op = optimizer.minimize(vertex_model_loss)\n",
    "face_model_optim_op = optimizer.minimize(face_model_loss)\n",
    "\n",
    "# Training loop\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for n in range(training_steps):\n",
    "    if n % check_step == 0:\n",
    "      v_loss, f_loss = sess.run((vertex_model_loss, face_model_loss))\n",
    "      print('Step {}'.format(n))\n",
    "      print('Loss (vertices) {}'.format(v_loss))\n",
    "      print('Loss (faces) {}'.format(f_loss))\n",
    "      v_samples_np, f_samples_np, b_np = sess.run(\n",
    "        (vertex_samples, face_samples, vertex_model_batch))\n",
    "      mesh_list = []\n",
    "      for n in range(1):\n",
    "        mesh_list.append(\n",
    "            {\n",
    "                'vertices': v_samples_np['vertices'][n][:v_samples_np['num_vertices'][n]],\n",
    "                'faces': data_utils.unflatten_faces(\n",
    "                    f_samples_np['faces'][n][:f_samples_np['num_face_indices'][n]])\n",
    "            }\n",
    "        )\n",
    "      data_utils.plot_meshes(mesh_list, ax_lims=0.5)\n",
    "    sess.run((vertex_model_optim_op, face_model_optim_op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "training.ipynb",
   "provenance": [
    {
     "file_id": "1QL8ib2FKPGUWFQbuX8AttUk-H34Al8Ue",
     "timestamp": 1591364245034
    },
    {
     "file_id": "1v_7DtLnpXrEhVbwZhzDiVQW7ghroi11Y",
     "timestamp": 1591355096822
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
